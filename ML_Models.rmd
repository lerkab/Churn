---
title: "Class3_Kabaloeva_Smirnova"
output:
  html_document: default
  pdf_document: default
---

```{r, include=FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='Figs/',
                      echo=TRUE, warning=FALSE, message=FALSE)
```

**1.1 DATA UPLOAD**
```{r}
#install.packages("readxl")
library(readxl)
#da <- read_xlsx("C:/Users/User/Documents/Учёба/ВШЭ/Магистратура/Machine Learning/Class 3/data3.xlsx")
da <- read_xlsx("C:/Users/lera/Desktop/Магистратура/3 модуль/Machine Learning/class 3/data.xlsx")
```

**1.2 CLASS OF VARIABLES**
```{r}
str(da)
da$loan_default=as.factor(da$loan_default)
da$code_gender=as.factor(da$code_gender)
da$flag_own_car=as.factor(da$flag_own_car)
da$flag_own_realty=as.factor(da$flag_own_realty)
da$name_income_type=as.factor(da$name_income_type)
da$name_education_type=as.factor(da$name_education_type)
da$name_family_status=as.factor(da$name_family_status)
da$name_housing_type=as.factor(da$name_housing_type)
```

```{r}
table(da$name_income_type)
da = dplyr::filter(da, name_income_type!='Maternity leave') 
da = dplyr::filter(da, name_income_type!='Unemployed') #removing categories that rarely occur in the sample so that there are no problems after splitting 
```

**2. a) DATA SPLITTING**
```{r}
#2/3*training, 1/3*test
set.seed(123)
index_train = sample(1:nrow(da), 2/3 * nrow(da))
training_set = da[index_train,]
test_set = da[-index_train,]
```

**2. b) ESTIMATING DECISION TREE MODEL WITH ALL VARIABLES (without cross-validation)**
```{r}
library(caret)

model1 = train(loan_default ~ ., method= "rpart", data = training_set)

prediction1 = predict(model1, newdata = test_set)
summary(prediction1)

#to plot a decision tree 
#install.packages("rpart.plot")
library(rpart.plot)
rpart.plot(model1$finalModel)
```
**2. c) CALCULATING ACCURACY AND AUC FOR MODEL 1**
```{r}
library(pROC)
AUC_model1 = auc(as.numeric(test_set$loan_default), as.numeric(prediction1))
AUC_model1

#confusion Matrix
library(e1071)
library(caret)
prediction1<-factor(prediction1)
test_set$loan_default=factor(test_set$loan_default)

confusionMatrix(prediction1,test_set$loan_default)
```

**2. d) ESTIMATING RANDOM FOREST MODEL FOR 50 TREES (without cross-validation)**
```{r}
#install.packages("randomForest")
library(randomForest)
model2 = train(loan_default ~ ., method= "rf", ntree = 50, data = training_set)
summary(model2)

prediction2 = predict(model2, newdata = test_set)
summary(prediction2)
```

**2. e) CALCULATING ACCURACY AND AUC FOR MODEL 2**
```{r}
AUC_model2 = auc(as.numeric(test_set$loan_default), as.numeric(prediction2))
AUC_model2

#confusion Matrix
prediction2<-factor(prediction2)
test_set$loan_default=factor(test_set$loan_default)

confusionMatrix(prediction2,test_set$loan_default)
```


**3. a) CROSS-VALIDATION**
```{r}
set.seed(456)
train.control = trainControl(method = "cv", number = 5)
```

**3. b) ESTIMATING DECISION TREE MODEL WITH ALL VARIABLES (with cross-validation)**
```{r}
model3 = train(loan_default ~ ., method= "rpart", data = da, trControl = train.control)

prediction3 = predict(model3, newdata = da)
summary(prediction3)

#to plot a decision tree 
library(rpart.plot)
rpart.plot(model3$finalModel)
```

**3. c) CALCULATING ACCURACY AND AUC FOR MODEL 3**
```{r}
#install.packages("cvAUC")
library(cvAUC)

cvAUC_model3 = cvAUC(as.numeric(prediction3), as.numeric(da$loan_default))
cvAUC_model3

#confusion Matrix
prediction3<-factor(prediction3)
da$loan_default=factor(da$loan_default)

confusionMatrix(prediction3,da$loan_default)
```


**3. d) ESTIMATING RANDOM FOREST MODEL FOR 50 TREES (with cross-validation)**
```{r}
#install.packages("randomForest")
library(randomForest)
model4 = train(loan_default ~ ., method= "rf", ntree = 50, data = da, trControl = train.control)
summary(model4)

prediction4 = predict(model4, newdata = da)
summary(prediction4)
```

**3. e) CALCULATING ACCURACY AND AUC FOR MODEL 4**
```{r}
cvAUC_model4 = cvAUC(as.numeric(prediction4), as.numeric(da$loan_default))
cvAUC_model4

#confusion Matrix
prediction4<-factor(prediction4)
da$loan_default=factor(da$loan_default)

confusionMatrix(prediction4,da$loan_default)
```


**4. CONCLUSION**

<br>AUC – Area Under Curve 
<br>The higher – the better

<br>AUC for model 1 (Decision tree without CV) = 0.543
<br>AUC for model 2 (Random forest without CV) = 0.5604
<br>AUC for model 3 (Decision tree with CV) = 0.5672581
<br>AUC for model 4 (Random forest with CV) = 0.6105196

<br>Cross-validation makes a model better. AUC value is higher.
<br>The most accurate prediction in the **Random forest model with cross-validation**.

<br>Accuracy for model 1 (Decision tree without CV) = 0.554 
<br>Accuracy for model 2 (Random forest without CV) = 0.5678
<br>Accuracy for model 3 (Decision tree with CV) = 0.5639
<br>Accuracy for model 4 (Random forest with CV) = 0.6192

<br>Accuracy value (from confusion Matrix) for Random forest model with cross-validation is higher too.
<br>The most accurate prediction in the **Random forest model with cross-validation** too.
<br>The worst model according to both indicators is Decision tree without CV.

**5. ESTIMATING TWO MORE MODELS**
**LOGISTIC REGRESSION MODEL (TRAINING DATA)**
```{r}
model5 <- glm(loan_default ~ ., family="binomial", data=training_set)
summary(model5)

prediction5 <- predict (model5, newdata=test_set, type="response")
prediction5 <-ifelse(prediction5<0.3,0,1)
summary(prediction5)
```
**CALCULATING ACCURACY AND AUC FOR MODEL 5**
```{r}
AUC_model5 = auc(as.numeric(test_set$loan_default), as.numeric(prediction5))
AUC_model5

#confusion Matrix
prediction5<-as.factor(prediction5)
test_set$loan_default=as.factor(test_set$loan_default)

confusionMatrix(prediction5, test_set$loan_default) 
```

**NAIVE BAYES CLASSIFIER (TRAINING DATA)**
```{r}
#install.packages("e1071")
library(e1071)
model6 <- naiveBayes(loan_default ~ ., data=training_set)

model6

prediction6 = predict(model6, newdata = test_set)
summary(prediction6)
```
**CALCULATING ACCURACY AND AUC FOR MODEL 6**
```{r}
AUC_model6 = auc(as.numeric(test_set$loan_default), as.numeric(prediction6))
AUC_model6

#confusion Matrix
prediction6<-factor(prediction6)
test_set$loan_default=factor(test_set$loan_default)

confusionMatrix(prediction6,test_set$loan_default)
```

**CONCLUSION ABOUT MODELS WITHOUT CROSS-VALIDATION**

<br>AUC for model 1 (Decision tree without CV) = 0.543
<br>AUC for model 2 (Random forest without CV) = 0.5604
<br>AUC for model 5 (Logistic regression without CV) = 0.5081
<br>AUC for model 6 (Naive Bayes Classifier without CV) = 0.5776


<br>Accuracy for model 1 (Decision tree without CV) = 0.554 
<br>Accuracy for model 2 (Random forest without CV) = 0.5678 
<br>Accuracy for model 5 (Logistic regression) = 0.527
<br>Accuracy for model 6 (Naïve Bayes classifier) = 0.5822 

<br>Looking at models **without cross-validation**, the most accurate prediction according to the AUC value in the **Naive Bayes Classifier**.
<br>Accuracy value (from confusion Matrix) for **Naive Bayes Classifier** is higher too.

<br>The worst model according to both indicators is Logistic regression.